---
layout: post
current: post
cover: assets/images/project-parking-analytics.jpg
navigation: True
title: 공영주차장 실시간 예측
date: 2017-05-22 15:33:00
tags: project
class: post-template
subclass: 'post tag-project'
logo: assets/images/slaysd.png
author: slaysd
---
<iframe src="//www.slideshare.net/slideshow/embed_code/key/2KTbf9MNEBOARj" width="640" height="522" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>

# 개요
빅데이터 분야로 나아가기 위해 아이디어를 내고 구현하게 된 첫번째 프로젝트로 중요한 의미가 있는 프로젝트였습니다. 당시 *알파고*가 큰 이슈를 가지고 있었고 기계학습에 대해 큰 관심이 주목되던 시기였습니다.
사실 *알파고*에 의해 주목되기 이전부터 Tensorflow를 공부하고 구현을 하고자 했었고, 이쪽 분야에 대한 정보들이 많이 쏟아져 나오면서 프로젝트를 실습하는데 필요한 정보들을 찾는데 어려움을 겪고 있던 찰나에 기계학습에 대한 정보에 이목이 집중되면서 기계학습에 관한 자료들을 얻는데 쉬워졌었습니다. 처음엔 데이터마이닝에 대한 강의와 인공지능 강의를 수강하면서 습득한 이론과 여러 기계학습 이론들을 익히고 실습하면서 많은
수행착오가 있었고 결과적으로 90% 이상의 정확도를 가진 모델을 학습할 수 있었지만 새로운 문제에 봉착하게 되었습니다. 당시 하둡과 같은 분산파일시스템에 대한 필요성의 이유를 모르고 있었기에 MongoDB를 이용하여
데이터를 수집하여 초기 데이터의 양이 비교적 적을 땐 모델 학습이 가능했었던 것이였습니다. 데이터의 양이 많아지면서 학습모델을 학습하는데 문제를 알게 되었고 하둡과 같은 분산파일시스템의 필요성을 절실히 느끼게 되었던 프로젝트였습니다.

결론적으로, 비교적 데이터의 양이 적을때는 성공한 프로젝트였지만 데이터의 양이 많아지면서 학습모델을 사용할 수가 없어 실패한 프로젝트였습니다. 하지만, 이를 통해 하둡과 같은 분산파일시스템의 필요성과 하둡에 대한 깊이 있는 학문을 갈구하게 되는 계기가 되었습니다.
* * *
# 개발환경
  * Python Tensorflow Library
  * Node.js + Express.js 프레임워크
    * Cron Module
  * R
  * MongoDB

* * *
# 프로젝트 기간
총 1개월(2016.03 ~ 2016.04)
* * *
# 소스코드
> 서비스하는 서버의 문제로 소스코드가 누락되었습니다ㅠ